{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка-данных\" data-toc-modified-id=\"Подготовка-данных-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка данных</a></span><ul class=\"toc-item\"><li><span><a href=\"#Описание-проекта\" data-toc-modified-id=\"Описание-проекта-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Описание проекта</a></span></li><li><span><a href=\"#Описание-данных\" data-toc-modified-id=\"Описание-данных-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Описание данных</a></span></li><li><span><a href=\"#Открываем-и-изучаем-файл\" data-toc-modified-id=\"Открываем-и-изучаем-файл-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Открываем и изучаем файл</a></span></li><li><span><a href=\"#Предобработка-данных\" data-toc-modified-id=\"Предобработка-данных-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Предобработка данных</a></span><ul class=\"toc-item\"><li><span><a href=\"#Проведение-лемматизации-и-обработка-символов\" data-toc-modified-id=\"Проведение-лемматизации-и-обработка-символов-1.4.1\"><span class=\"toc-item-num\">1.4.1&nbsp;&nbsp;</span>Проведение лемматизации и обработка символов</a></span></li><li><span><a href=\"#Разбивка-на-обучающую-и-тестовую-выборки\" data-toc-modified-id=\"Разбивка-на-обучающую-и-тестовую-выборки-1.4.2\"><span class=\"toc-item-num\">1.4.2&nbsp;&nbsp;</span>Разбивка на обучающую и тестовую выборки</a></span></li><li><span><a href=\"#Создание-корпуса\" data-toc-modified-id=\"Создание-корпуса-1.4.3\"><span class=\"toc-item-num\">1.4.3&nbsp;&nbsp;</span>Создание корпуса</a></span></li><li><span><a href=\"#Добавление-стоп-слов\" data-toc-modified-id=\"Добавление-стоп-слов-1.4.4\"><span class=\"toc-item-num\">1.4.4&nbsp;&nbsp;</span>Добавление стоп-слов</a></span></li><li><span><a href=\"#Датафрейм-для-сбора-результатов\" data-toc-modified-id=\"Датафрейм-для-сбора-результатов-1.4.5\"><span class=\"toc-item-num\">1.4.5&nbsp;&nbsp;</span>Датафрейм для сбора результатов</a></span></li><li><span><a href=\"#Функция-для-обучения-моделей\" data-toc-modified-id=\"Функция-для-обучения-моделей-1.4.6\"><span class=\"toc-item-num\">1.4.6&nbsp;&nbsp;</span>Функция для обучения моделей</a></span></li></ul></li><li><span><a href=\"#Вывод\" data-toc-modified-id=\"Вывод-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Вывод</a></span></li></ul></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#Векторизация\" data-toc-modified-id=\"Векторизация-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Векторизация</a></span></li><li><span><a href=\"#Обучение-с-помощью-TF-IDF\" data-toc-modified-id=\"Обучение-с-помощью-TF-IDF-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Обучение с помощью <code>TF-IDF</code></a></span></li><li><span><a href=\"#Обучение-с-помощью-DistilBert\" data-toc-modified-id=\"Обучение-с-помощью-DistilBert-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Обучение с помощью <code>DistilBert</code></a></span></li></ul></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Описание проекта"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин **«Викишоп»** запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Описание данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные находятся в файле **`toxic_comments.csv`**. Столбец **`text`** в нём содержит текст комментария, а **`toxic`** — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Открываем и изучаем файл"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем необходимые в работе библиотеки и модули:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Алексей\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "import re\n",
    "from tqdm import notebook\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# откроем датасет и сохраним его в новой переменной\n",
    "df = pd.read_csv('C:\\\\Users\\\\Алексей\\\\Downloads\\\\toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# выведем первые пять строк таблицы\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# Выведем информацию по датасету\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143346\n",
       "1     16225\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# посмотрим на дисбаланс классов\n",
    "df['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим дисбаланс классов в данных большой."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Проведение лемматизации и обработка символов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В предобработке данных проведем лемматизацию, удалим цифры, а также знаки и лишние пробелы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# напишем функцию по предобработке\n",
    "def data_preprocessing(text):\n",
    "    tokenized = nltk.word_tokenize(text)\n",
    "    joined = ' '.join(tokenized)\n",
    "    text_only = re.sub(r'[^a-zA-Z]', ' ', joined)\n",
    "    final = ' '.join(text_only.split())\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# посмторим как выглядят данные перед обработкой\n",
    "df['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "683fe21f161d42bea469958bfe4ea395",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/159571 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# обработаем данные и сохраним результат в новом столбце\n",
    "notebook.tqdm.pandas() \n",
    "df['text_final'] = df['text'].progress_apply(data_preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Explanation Why the edits made under my username Hardcore Metallica Fan were reverted They were n t vandalisms just closure on some GAs after I voted at New York Dolls FAC And please do n t remove the template from the talk page since I m retired now'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# посмторим как выглядят данные после обработки\n",
    "df['text_final'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Разбивка на обучающую и тестовую выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_df = df['text_final'] # признаки\n",
    "y_df = df['toxic'] # целевое значение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((119678,), (39893,), (119678,), (39893,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# задаем значение random_state\n",
    "rand = 13\n",
    "\n",
    "# разбиваем на выборки и выводим на экран\n",
    "x_train_df, x_test_df, y_train_df, y_test_df = train_test_split(x_df, y_df, random_state=rand, stratify=y_df)\n",
    "x_train_df.shape, x_test_df.shape, y_train_df.shape, y_test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на распределение классов в выборках:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Распределение классов в обучающей выборке:\n",
      "Класс '0' = 89.83188221728304\n",
      "Класс '1' = 10.168117782716957\n",
      "\n",
      "Распределение классов в тестовой выборке:\n",
      "Класс '0' = 89.83280274734916\n",
      "Класс '1' = 10.16719725265084\n"
     ]
    }
   ],
   "source": [
    "print('Распределение классов в обучающей выборке:')\n",
    "print(\"Класс '0' =\", y_train_df.value_counts()[0] / y_train_df.value_counts().sum() * 100)\n",
    "print(\"Класс '1' =\", y_train_df.value_counts()[1] / y_train_df.value_counts().sum() * 100)\n",
    "print()\n",
    "print('Распределение классов в тестовой выборке:')\n",
    "print(\"Класс '0' =\", y_test_df.value_counts()[0] / y_test_df.value_counts().sum() * 100)\n",
    "print(\"Класс '1' =\", y_test_df.value_counts()[1] / y_test_df.value_counts().sum() * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Создание корпуса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим корпус:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_df_corpus = x_train_df.values.astype('U')\n",
    "x_test_df_corpus = x_test_df.values.astype('U')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Добавление стоп-слов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим стоп-слова:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Алексей\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество стоп-слов =  179\n"
     ]
    }
   ],
   "source": [
    "# загрузим список стоп-слов\n",
    "nltk.download('stopwords')\n",
    "# вызовем функцию stopwords.words(), передадим ей аргумент 'english', то есть англоязычные стоп-слова\n",
    "stopwords = set(stopwords.words('english'))\n",
    "print(\"Количество стоп-слов = \", len(stopwords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Датафрейм для сбора результатов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовим датафрейм для сбора результатов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\n",
    "    'Preprocessing model' : [],\n",
    "    'Learning model' : [],\n",
    "    'Train f1 score' : [],\n",
    "    'Test f1 score' : []\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    LogisticRegression(max_iter=1000),\n",
    "    lgb.LGBMClassifier(n_estimators = 1000, learning_rate = 0.1)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Функция для обучения моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем функцию для обучения моделей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_training_models(models_list, x_train, y_train, x_test, y_test, preprocess_model : str):\n",
    "    for i in models_list:\n",
    "        clf_gs = GridSearchCV(i, {}, cv=5, scoring='f1')\n",
    "        clf_gs.fit(x_train,y_train)\n",
    "        \n",
    "        train_f1_score = f1_score(y_train, clf_gs.predict(x_train))\n",
    "        test_f1_score = f1_score(y_test, clf_gs.predict(x_test))\n",
    "        \n",
    "        name = str(i).split(sep='(')[0]\n",
    "        \n",
    "        globals()['results'] = globals()['results'].append({\n",
    "            'Preprocessing model' : preprocess_model, 'Learning model' : name, \n",
    "            'Train f1 score' : round(train_f1_score, 2), 'Test f1 score' : round(test_f1_score, 2)}, \n",
    "            ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы открыли и изучили файл с данными, а также сохранили его в отдельной переменной. Провели предобработку данных: лемматизировали и обработали символы путем удаления цифр, знаков и лишних пробелов, а также произвели разбивку данных на обучающую и тестовую выборки. Создали корпус и добавили стоп-слова. Подготовили датафрейм для сбора результатов и написали функцию для обучения моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Векторизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим счетчик:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# передадим список стоп-слов в счётчик векторов CountVectorizer()\n",
    "vectorizer = CountVectorizer(stop_words=stopwords, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# передадим счётчику корпус текстов через функцию fit_transform()\n",
    "x_train_df_vectorized = vectorizer.fit_transform(x_train_df_corpus)\n",
    "x_test_df_vectorized = vectorizer.transform(x_test_df_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119678, 142782)\n",
      "\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train_df_vectorized.shape)\n",
    "print()\n",
    "print(x_train_df_vectorized[:5].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-361fd388f50a>:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  globals()['results'] = globals()['results'].append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9min 5s\n",
      "Parser   : 266 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-361fd388f50a>:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  globals()['results'] = globals()['results'].append({\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "function_training_models(models, \n",
    "                         x_train_df_vectorized, y_train_df, \n",
    "                         x_test_df_vectorized, y_test_df, \n",
    "                         preprocess_model = 'CountVectorizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Preprocessing model</th>\n",
       "      <th>Learning model</th>\n",
       "      <th>Train f1 score</th>\n",
       "      <th>Test f1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Preprocessing model      Learning model  Train f1 score  Test f1 score\n",
       "0     CountVectorizer  LogisticRegression            0.90           0.75\n",
       "1     CountVectorizer      LGBMClassifier            0.92           0.76"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[-2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение с помощью `TF-IDF`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем обучение с помощью TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = TfidfVectorizer(stop_words=stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_df_tf_idf = tf_idf.fit_transform(x_train_df)\n",
    "x_test_df_tf_idf = tf_idf.transform(x_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119678, 142782)\n",
      "\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train_df_tf_idf.shape)\n",
    "print()\n",
    "print(x_train_df_tf_idf[:5].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-361fd388f50a>:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  globals()['results'] = globals()['results'].append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 25min 40s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-361fd388f50a>:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  globals()['results'] = globals()['results'].append({\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "function_training_models(models, x_train_df_tf_idf, y_train_df, x_test_df_tf_idf, y_test_df,\n",
    "             preprocess_model = 'TfidfVectorizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Preprocessing model</th>\n",
       "      <th>Learning model</th>\n",
       "      <th>Train f1 score</th>\n",
       "      <th>Test f1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Preprocessing model      Learning model  Train f1 score  Test f1 score\n",
       "2     TfidfVectorizer  LogisticRegression            0.76           0.72\n",
       "3     TfidfVectorizer      LGBMClassifier            0.95           0.77"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[-2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение с помощью `DistilBert`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для ускорения обучения модели `Bert`, возьмем срез из 2000 строк из основного датафрейма.\n",
    "\n",
    "Проверим сохранен ли в срезе дисбаланс классов основного датафрейма:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Распределение классов во всем датасете:\n",
      "89.83211235124176\n",
      "10.167887648758233\n",
      "\n",
      "Распределение классов в срезе для Bert:\n",
      "89.5\n",
      "10.5\n"
     ]
    }
   ],
   "source": [
    "print('Распределение классов во всем датасете:')\n",
    "print(df['toxic'].value_counts()[0] / df['toxic'].value_counts().sum() * 100)\n",
    "print(df['toxic'].value_counts()[1] / df['toxic'].value_counts().sum() * 100)\n",
    "print()\n",
    "print('Распределение классов в срезе для Bert:')\n",
    "print(df['toxic'][:2000].value_counts()[0] / df['toxic'][:2000].value_counts().sum() * 100)\n",
    "print(df['toxic'][:2000].value_counts()[1] / df['toxic'][:2000].value_counts().sum() * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class, tokenizer_class, pretrained_weights = (transformers.DistilBertModel, transformers.DistilBertTokenizer, \n",
    "                                                    'distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf0698dd9cca4554ae3a6c5b3d1e2b4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bef6dca59344cbe886d851b3c1b00a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc9992533c8b488184f76bb9df0f27dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4da36fd19cf74062877d5ab7caa42a75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/256M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d1bf128c19a4e7eb946fe68d7aced97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized = df['text_final'][:2000].progress_apply(lambda x: tokenizer.encode(x[:512], add_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded = np.array([i + [0]*(512-len(i)) for i in tokenized.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(padded[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2000, 512), (2000, 512))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "padded.shape, attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "embeddings = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ac2874caf494dfb87a140119b479718",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n",
    "    batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)])\n",
    "    attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "    embeddings.append(batch_embeddings[0][:,0,:].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2000, 768), (2000,))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_bert = np.concatenate(embeddings)\n",
    "y_bert = df['toxic'][:2000]\n",
    "x_bert.shape, y_bert.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_bert, x_test_bert, y_train_bert, y_test_bert = train_test_split(x_bert, y_bert, random_state=rand, stratify=y_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-361fd388f50a>:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  globals()['results'] = globals()['results'].append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 52s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-361fd388f50a>:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  globals()['results'] = globals()['results'].append({\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "function_training_models(models, x_train_bert, y_train_bert, x_test_bert, y_test_bert,\n",
    "             preprocess_model = 'DistilBert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Preprocessing model</th>\n",
       "      <th>Learning model</th>\n",
       "      <th>Train f1 score</th>\n",
       "      <th>Test f1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DistilBert</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DistilBert</td>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Preprocessing model      Learning model  Train f1 score  Test f1 score\n",
       "4          DistilBert  LogisticRegression            0.84           0.75\n",
       "5          DistilBert      LGBMClassifier            1.00           0.62"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[-2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на таблицу результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Preprocessing model</th>\n",
       "      <th>Learning model</th>\n",
       "      <th>Train f1 score</th>\n",
       "      <th>Test f1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DistilBert</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DistilBert</td>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Preprocessing model      Learning model  Train f1 score  Test f1 score\n",
       "3     TfidfVectorizer      LGBMClassifier            0.95           0.77\n",
       "1     CountVectorizer      LGBMClassifier            0.92           0.76\n",
       "0     CountVectorizer  LogisticRegression            0.90           0.75\n",
       "4          DistilBert  LogisticRegression            0.84           0.75\n",
       "2     TfidfVectorizer  LogisticRegression            0.76           0.72\n",
       "5          DistilBert      LGBMClassifier            1.00           0.62"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sort_values('Test f1 score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наилучший результат показала модель **`LGBMClassifier`** на предобработанном тексте с помощью модели **`TfidfVectorizer`**. Возможно `DistilBert` показал плохой результат из-за того, что был обучен всего на 2000 строках, в то время как остальные модели на всем датафрейме."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
