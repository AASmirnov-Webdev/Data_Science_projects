# Определение токсичных комментариев

## Описание проекта
Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. 

Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.

Постройте модель со значением метрики качества F1 не меньше 0.75. 

## Описание данных

Данные находятся в файле `/datasets/toxic_comments.csv`.

Столбец `text` содержит текст комментария, а `toxic` — целевой признак.

---
# Вывод
Наилучший результат показала модель **`LGBMClassifier`** на предобработанном тексте с помощью модели **`TfidfVectorizer`**. Возможно `DistilBert` показал плохой результат из-за того, что был обучен всего на 2000 строках, в то время как остальные модели на всем датафрейме.

## Используемые библиотеки
*pandas, numpy, stopwords, WordNetLemmatizer, torch, nltk, transformers, sklearn, lightgbm, notebook*
